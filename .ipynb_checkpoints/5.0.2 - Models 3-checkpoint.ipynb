{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIAYbYajk1w9"
   },
   "source": [
    "# Building Blocks of Models\n",
    "- Convolution & Pooling\n",
    "- Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4151,
     "status": "ok",
     "timestamp": 1543983074896,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "GVU5-yp3N89I",
    "outputId": "3d971b90-4a62-4564-d3a2-9259fa52b587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1543981967794,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "8yy37hEYOEiQ",
    "outputId": "94a42058-3871-4e5f-8d1b-6a0554a3a75a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyv2Sy5WO8lK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAqYXyzcT-OJ"
   },
   "source": [
    "## 1. Convolution & Pooling \n",
    "Convolution and pooling are fundamental operations for building CNN models. There are a number of parameters and if their definitions are not clear, it could lead to great confusion.\n",
    "- Parameters for convolution (pooling) layers\n",
    "  - **stride:** how many \"steps\" that the filter makes for each advance\n",
    "  - **kernel size**: how large is the kernel (filter) is\n",
    "  - **number of filters (channels):** designates the \"depth\" of the data. Most image inputs have three filters (RGB)\n",
    "  - **padding:** how to pad the input sample with zero in the border\n",
    "- How to calculate output size of convolution/pooling operation\n",
    "  <br> \n",
    "*(W - F + 2P)/S + 1* <br>\n",
    "  - *W*: input size\n",
    "  - *F*: kernel size\n",
    "  - *P*: padding \n",
    "  - *S*: stride\n",
    "  \n",
    "![alt text](https://user-images.githubusercontent.com/22738317/34081046-c3a97518-e347-11e7-98fe-929f602ee857.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoCXfOh1RQun"
   },
   "source": [
    "### 1. Convolution & Pooling 1D\n",
    "\n",
    "- ```torch.nn.Conv1d()```: 1D convolution\n",
    "  - Input: (N, Fi, Li): basically, each input is ```Fi``` vectors of length ```Li```\n",
    "    - N: batch size\n",
    "    - Fi: number of input filters (or channels)\n",
    "    - Li: length of input sequence\n",
    "  - Output: (N, Fo, Lo): each output is ```Fo``` vectors of length ```Lo```\n",
    "    - N: batch size\n",
    "    - Fo: number of output filters (or channels)\n",
    "    - Lo: length of output sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1323,
     "status": "ok",
     "timestamp": 1543981975275,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "kp_YDg0aQQ0e",
    "outputId": "115d3bbd-055e-416b-c550-b1c9ffa45bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 10])\n"
     ]
    }
   ],
   "source": [
    "# case 1 - kernel size = 1\n",
    "conv1d = nn.Conv1d(16, 32, kernel_size = 1)\n",
    "\n",
    "x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n",
    "print(conv1d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1538897442176,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "LMcGMyJNSzSA",
    "outputId": "5b0b68e1-6b30-4715-8693-96fc6bd724dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 13])\n"
     ]
    }
   ],
   "source": [
    "# case 2 - kernel size = 2, stride = 1\n",
    "conv1d = nn.Conv1d(16, 32, kernel_size = 2, padding = 2)\n",
    "\n",
    "x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n",
    "print(conv1d(x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1538897465647,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "Irn1yF5lb3HO",
    "outputId": "8a5e5025-bee4-4949-d115-63fdf9e1e70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 7])\n"
     ]
    }
   ],
   "source": [
    "# case 2 - kernel size = 2, stride = 2\n",
    "conv1d = nn.Conv1d(16, 64, kernel_size = 2, stride = 2, padding = 2)\n",
    "\n",
    "x = torch.ones(128, 16, 10)   # input: batch_size = 128, num_filters = 16, seq_length = 10\n",
    "print(conv1d(x).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BF4TJ0Of1G1"
   },
   "source": [
    "### Convolution & Pooling 2D\n",
    "- ```torch.nn.Conv2d()```:  2D convolution\n",
    "  - Largely siimilar to 1D-convolution, but input and outputs are 2-dimensional, rather than 1-dimensional\n",
    "- Image data in Pytorch\n",
    "  - ```Conv2d()``` is the basic building block of modern CNNs to process image, such as GoogleNet or ResNet\n",
    "  - In Pytorch, images usually have shape of **\\[depth, height, width\\]**\n",
    "    - depth corresponds to the number of filters (kernels)\n",
    "    - width and height represent the size of an image. When the image is square (e.g., in CIFAR10), width = height\n",
    "  \n",
    "  ![alt text](http://cs231n.github.io/assets/cnn/cnn.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1980,
     "status": "ok",
     "timestamp": 1543983461231,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "ddO_D_L2b81J",
    "outputId": "923e57f9-8ced-4e2d-eba0-3074893cffcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 10, 10])\n",
      "torch.Size([128, 32, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# case 1 - kernel size = 1\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)\n",
    "\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = (1, 1))  # same as kernel size = 1\n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())       # input and output size are equal when kernel_size = 1 (assuming no padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1543983497981,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "kvg4w7Q7lJBT",
    "outputId": "1e6019f5-6756-4ad0-aa83-648f1fbd10f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "# case 2 - kernel size = 2\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = 2, padding = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1543983527824,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "WMZooMlVljmy",
    "outputId": "4f35276d-58de-4671-c6e2-4a6087216385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 9, 10])\n"
     ]
    }
   ],
   "source": [
    "# case 3 - differing kernel size\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = (2, 1))  # if kernel size is integer, width and height are equal (i.e., square kernel) \n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())     # non-square output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1430,
     "status": "ok",
     "timestamp": 1543983641407,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "9A514b51lsxS",
    "outputId": "f3ae5c31-ba42-41d4-b8b4-456ce43f1f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# case 4 - kernel size = 3\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = (3, 3), padding = 1)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())     # input and output size are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1550,
     "status": "ok",
     "timestamp": 1543983657522,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "91PuKukfmK07",
    "outputId": "1e0560c0-49d5-4580-d6d5-0a5cde6abd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# case 4 - kernel size = 3, stride = 2\n",
    "conv2d = nn.Conv2d(16, 32, kernel_size = (3, 3), stride = 2)  # if kernel size is integer, width and height are equal (i.e., square kernel) \n",
    "\n",
    "x = torch.ones(128, 16, 10, 10)   # input: batch_size = 128, num_filters = 16, height = 10, width = 10\n",
    "print(conv2d(x).size())     # input and output size are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxSuAXXRmjSJ"
   },
   "source": [
    "## 2. Padding\n",
    "- Zero padding can be applied in convolution/pooling as we have seen above. But custom padding can be applied as well\n",
    "  - ```nn.ConstandPad1d(padding, value)```: apply constant padding on 1D data\n",
    "    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```))\n",
    "    - ```value```: the value of padding\n",
    "  - ```nn.ConstantPad2d(padding, value)```: apply constant padding on 2D data\n",
    "    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```, ```paddingTop```, ```padingBottom```))\n",
    "    - ```value```: the value of padding\n",
    "  - ```nn.ZeroPad2d(padding)```: apply zero padding on 2D data \n",
    "    - ```padding```: the shape of padding (if tuple, (```padingLeft```, ```padingRight```, ```paddingTop```, ```padingBottom```))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1543984263422,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "l8v3fQXooGyk",
    "outputId": "f9380ca5-60ba-421c-c284-51b432558386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7500, 1.0000, 1.0000, 1.0000, 0.7500]]])\n"
     ]
    }
   ],
   "source": [
    "p = nn.ConstantPad1d(1, 0.75)  # 1d padding with constant 0.75\n",
    "x = torch.ones(1, 1, 3)\n",
    "print(p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1543984484897,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "QCt72l7LpNoc",
    "outputId": "bce9e603-ef1b-4bef-9f03-70b4f3c7e2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1., -1.,  1.,  1.,  1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1., -1., -1.],\n",
      "          [-1., -1.,  1.,  1.,  1., -1., -1.]]]])\n"
     ]
    }
   ],
   "source": [
    "p = nn.ConstantPad2d((2, 2, 0, 0), -1)  # 2d padding with -1 (on right and left)\n",
    "x = torch.ones(1, 1, 3, 3)\n",
    "print(p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1516,
     "status": "ok",
     "timestamp": 1543984158701,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "k7ucMutomgGh",
    "outputId": "e0f5ce1a-51c2-4e53-c331-4a4172ac665d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 1., 1., 1.],\n",
      "          [0., 1., 1., 1.],\n",
      "          [0., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "p = nn.ZeroPad2d((1,0,0,0))  # apply zero padding only on the left of first column\n",
    "x = torch.ones(1, 1, 3, 3)\n",
    "print(p(x))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch-model-basics-3 [CNN].ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
